#  Audio Processing Features

## Quick Navigation

- [overview](1-overview.md)
- [backend-api-(app.py)](2-backend-api-(app.py).md)
  - [api-endpoints](2.1-api-endpoints.md)
  - [mentor-class](2.2-mentor-class.md)
- [user-interfaces](3-user-interfaces.md)
  - [chat-interface](3.1-chat-interface.md)
  - [progress-dashboard](3.2-progress-dashboard.md)
  - [admin-interface](3.3-admin-interface.md)
- [database-architecture](4-database-architecture.md)
  - [user-and-progress-models](4.1-user-and-progress-models.md)
  - [database-migrations](4.2-database-migrations.md)
- [rag-system](5-rag-system.md)
  - [vector-database](5.1-vector-database.md)
  - [language-models](5.2-language-models.md)
- [deployment-and-configuration](6-deployment-and-configuration.md)
  - [dependencies](6.1-dependencies.md)
  - [audio-processing-features](6.2-audio-processing-features.md)

## Table of Contents

- [Audio Processing Features](#audio-processing-features)
  - [1. Overview of Audio Processing Capabilities](#1-overview-of-audio-processing-capabilities)
  - [2. Speech Recognition System](#2-speech-recognition-system)
    - [2.1 User Interface Components](#21-user-interface-components)
    - [2.2 Technical Implementation](#22-technical-implementation)
      - [Recording Implementation Details](#recording-implementation-details)
    - [2.3 API Integration](#23-api-integration)
  - [3. Text-to-Speech System](#3-text-to-speech-system)
    - [3.1 User Interface](#31-user-interface)
    - [3.2 Technical Implementation](#32-technical-implementation)
      - [TTS Implementation Details](#tts-implementation-details)
  - [4. Integration with Chat Interface](#4-integration-with-chat-interface)
    - [4.1 Audio Recording in the Chat Flow](#41-audio-recording-in-the-chat-flow)
    - [4.2 Text-to-Speech in the Chat Flow](#42-text-to-speech-in-the-chat-flow)
  - [5. Configuration and API Keys](#5-configuration-and-api-keys)
  - [6. Error Handling](#6-error-handling)
  - [7. Summary and Limitations](#7-summary-and-limitations)
    - [Limitations:](#limitations)

# Audio Processing Features

Relevant source files

* [Misc/json.py](https://github.com/JATAYU000/MARS-labs/blob/d77026a0/Misc/json.py)
* [Misc/temp.html](https://github.com/JATAYU000/MARS-labs/blob/d77026a0/Misc/temp.html)
* [api/templates/chat.html](https://github.com/JATAYU000/MARS-labs/blob/d77026a0/api/templates/chat.html)

This document details the audio processing capabilities implemented in the MARS-labs chat interface. The system supports bidirectional audio communication through speech recognition (voice-to-text) and text-to-speech functionality, allowing users to interact with the learning platform using natural voice commands and listen to responses.

## 1. Overview of Audio Processing Capabilities

The MARS-labs platform integrates two primary audio processing features:

1. **Speech Recognition**: Allows users to record voice input that gets transcribed to text
2. **Text-to-Speech**: Converts bot responses to spoken audio for accessibility

These features create a more accessible and natural interaction model for educational content, particularly important for language learning and accessibility purposes.

Sources: [api/templates/chat.html416-531](https://github.com/JATAYU000/MARS-labs/blob/d77026a0/api/templates/chat.html#L416-L531) [api/templates/chat.html599-828](https://github.com/JATAYU000/MARS-labs/blob/d77026a0/api/templates/chat.html#L599-L828)

## 2. Speech Recognition System

The speech recognition system captures audio from the user's microphone, processes it, and converts it to text that can be sent as a query to the AI assistant.

### 2.1 User Interface Components

The UI for audio recording includes:

* A microphone button in the chat input area
* A recording modal with status indicators
* Recording time display with automatic cutoff at 2 minutes
* Cancel and stop buttons for user control

Sources: [api/templates/chat.html599-605](https://github.com/JATAYU000/MARS-labs/blob/d77026a0/api/templates/chat.html#L599-L605) [api/templates/chat.html610-622](https://github.com/JATAYU000/MARS-labs/blob/d77026a0/api/templates/chat.html#L610-L622) [api/templates/chat.html747-821](https://github.com/JATAYU000/MARS-labs/blob/d77026a0/api/templates/chat.html#L747-L821)

### 2.2 Technical Implementation

The speech recognition system follows this workflow:

1. **Audio Capture**: Using the MediaRecorder API from browser's WebRTC capabilities
2. **Audio Processing**: Collecting audio chunks and creating a webm blob
3. **API Integration**: Uploading to AssemblyAI for transcription
4. **Result Handling**: Displaying transcribed text in the chat input field

#### Recording Implementation Details

Sources: [api/templates/chat.html747-781](https://github.com/JATAYU000/MARS-labs/blob/d77026a0/api/templates/chat.html#L747-L781) [api/templates/chat.html801-828](https://github.com/JATAYU000/MARS-labs/blob/d77026a0/api/templates/chat.html#L801-L828)

### 2.3 API Integration

The system integrates with AssemblyAI's speech recognition API through a two-step process:

1. **Audio Upload**: The recording is first uploaded to AssemblyAI's servers
2. **Transcription Request**: The system then initiates transcription using the upload URL

Sources: [api/templates/chat.html830-877](https://github.com/JATAYU000/MARS-labs/blob/d77026a0/api/templates/chat.html#L830-L877) [Misc/temp.html76-135](https://github.com/JATAYU000/MARS-labs/blob/d77026a0/Misc/temp.html#L76-L135)

## 3. Text-to-Speech System

The text-to-speech system converts bot responses to audio that can be played back to the user.

### 3.1 User Interface

* A speaker button appears next to messages
* Clicking this button triggers text-to-speech conversion of the latest bot message
* Audio is played through the user's device speakers

Sources: [api/templates/chat.html513-530](https://github.com/JATAYU000/MARS-labs/blob/d77026a0/api/templates/chat.html#L513-L530) [api/templates/chat.html594](https://github.com/JATAYU000/MARS-labs/blob/d77026a0/api/templates/chat.html#L594-L594) [api/templates/chat.html659-671](https://github.com/JATAYU000/MARS-labs/blob/d77026a0/api/templates/chat.html#L659-L671)

### 3.2 Technical Implementation

The text-to-speech functionality is implemented using a third-party API service (RapidAPI). The system:

1. Extracts text from the latest bot message
2. Sends the text to the TTS API
3. Receives an audio URL in response
4. Sets this URL as the source for an audio element
5. Plays the audio automatically

#### TTS Implementation Details

The implementation creates a Promise-based function that handles the API request and audio playback:

Sources: [api/templates/chat.html678-745](https://github.com/JATAYU000/MARS-labs/blob/d77026a0/api/templates/chat.html#L678-L745)

## 4. Integration with Chat Interface

The audio processing features are tightly integrated with the chat interface, enhancing the user experience.

### 4.1 Audio Recording in the Chat Flow

Sources: [api/templates/chat.html598-607](https://github.com/JATAYU000/MARS-labs/blob/d77026a0/api/templates/chat.html#L598-L607) [api/templates/chat.html610-622](https://github.com/JATAYU000/MARS-labs/blob/d77026a0/api/templates/chat.html#L610-L622) [api/templates/chat.html747-828](https://github.com/JATAYU000/MARS-labs/blob/d77026a0/api/templates/chat.html#L747-L828)

### 4.2 Text-to-Speech in the Chat Flow

Sources: [api/templates/chat.html536](https://github.com/JATAYU000/MARS-labs/blob/d77026a0/api/templates/chat.html#L536-L536) [api/templates/chat.html594](https://github.com/JATAYU000/MARS-labs/blob/d77026a0/api/templates/chat.html#L594-L594) [api/templates/chat.html659-671](https://github.com/JATAYU000/MARS-labs/blob/d77026a0/api/templates/chat.html#L659-L671)

## 5. Configuration and API Keys

The audio processing features rely on third-party APIs that require authentication:

| API Service | Purpose | API Key Variable | Location |
| --- | --- | --- | --- |
| AssemblyAI | Speech-to-text transcription | `API_KEY` | [api/templates/chat.html650](https://github.com/JATAYU000/MARS-labs/blob/d77026a0/api/templates/chat.html#L650-L650) |
| RapidAPI TTS Service | Text-to-speech conversion | `apiKey` | [api/templates/chat.html683](https://github.com/JATAYU000/MARS-labs/blob/d77026a0/api/templates/chat.html#L683-L683) |

**Note**: In a production environment, these API keys should be stored securely on the server side rather than embedded in client-side JavaScript.

Sources: [api/templates/chat.html650-651](https://github.com/JATAYU000/MARS-labs/blob/d77026a0/api/templates/chat.html#L650-L651) [api/templates/chat.html683-684](https://github.com/JATAYU000/MARS-labs/blob/d77026a0/api/templates/chat.html#L683-L684)

## 6. Error Handling

The audio processing system includes error handling for various scenarios:

1. **Microphone Access Errors**: If permission is denied or the device doesn't have a microphone
2. **Upload Failures**: If the audio file can't be uploaded to AssemblyAI
3. **Transcription Errors**: If the speech recognition process fails
4. **TTS API Errors**: If text-to-speech conversion fails
5. **Playback Errors**: If audio can't be played back due to browser limitations

Error messages are displayed to the user in the chat interface to provide feedback when issues occur.

Sources: [api/templates/chat.html766-770](https://github.com/JATAYU000/MARS-labs/blob/d77026a0/api/templates/chat.html#L766-L770) [api/templates/chat.html818-827](https://github.com/JATAYU000/MARS-labs/blob/d77026a0/api/templates/chat.html#L818-L827) [api/templates/chat.html734-743](https://github.com/JATAYU000/MARS-labs/blob/d77026a0/api/templates/chat.html#L734-L743)

## 7. Summary and Limitations

The audio processing features in MARS-labs provide a natural language interface for interacting with the educational platform, enhancing accessibility and user experience. The implementation leverages third-party APIs (AssemblyAI and RapidAPI) to provide high-quality speech recognition and text-to-speech capabilities.

### Limitations:

* **API Dependency**: The system relies on external services which may have usage limits or require paid subscriptions
* **Network Requirements**: Both features require an active internet connection to function
* **Browser Compatibility**: The features depend on modern browser APIs like MediaRecorder which may not be available in older browsers
* **Language Support**: The current implementation primarily supports English, with limited multilingual capabilities

Sources: [api/templates/chat.html650-651](https://github.com/JATAYU000/MARS-labs/blob/d77026a0/api/templates/chat.html#L650-L651) [api/templates/chat.html683-684](https://github.com/JATAYU000/MARS-labs/blob/d77026a0/api/templates/chat.html#L683-L684)